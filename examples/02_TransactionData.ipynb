{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 2\n",
    "## Transaction Data\n",
    "### Preliminaries\n",
    "We only need this because the examples folder is a subdirectory of the `bestPy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n",
    "Since we are not going to actually recommend anything in the present chapter, we are just going tom import the relevant datastructure from the aptly named sub-package `bestPy.datastructures`. The primary data structure is _Transaction_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bestPy.datastructures import Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With transaction data, we simply mean a list of sales from your store with each entry consiting of a timestamp, a unique customer ID, and a unique article ID. Saved, for example, into a _comma-separated values_ (CSV) file, such a transaction list could look something like this:\n",
    "\n",
    "```\n",
    "Timestamp|Customer ID|Article\n",
    "=============================\n",
    "1331072795;4;AC016EL50CPHALID-1749\n",
    "1331074425;1;AC016EL67BJWALID-932\n",
    "1331306282;12;SA848EL83DOYALID-2416\n",
    "1331306282;12;BL152EL82CRXALID-1817\n",
    "1331306313;11;CA189EL29AGOALID-170\n",
    "1331306332;11;LE629EL54ANHALID-345\n",
    "1331306341;10;OL756EL65HDYALID-4834\n",
    "1331306414;7;OL756EL55HAMALID-4744\n",
    "```\n",
    "Since CSV is indeed a common way of storing such information, it is also one of the currently supported data sources for `bestPy`.\n",
    "\n",
    "### From CSV file\n",
    "To read from a CSV file, we presuppose that the ordering of the columns is _timestamp_; _customer ID_; _article ID_\n",
    "and that there are no columns other than these three. Data can then be read in by instantiating a new `Transactions` object _via_ the class method `from_csv()`, which takes the path to and name of the CSV file as argument, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not interpret transaction on line 1. Skipping.\n",
      "WARNING:root:Could not interpret transaction on line 2. Skipping.\n"
     ]
    }
   ],
   "source": [
    "file = 'examples_data.csv'\n",
    "data = Transactions.from_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooohps! What happened here? No worries! The reader just detected that the first two lines in the file were the column headers and the separation line (as in the example above), neither of which is interpreted as a valid transaction. More about that shortly.\n",
    "\n",
    "First, we note that Tab completion on the method `from_csv()` reveals a second argument `separator` (defaulting to ';'), which allows specifying the character(s) separating the columns in the CSV file. If, for example, an actual comma were used instead of the semicolon in the example above, one would simply write\n",
    "\n",
    "```python\n",
    "file_with_commas = '/path/to/file_with_commas.csv'\n",
    "data = Transactions.from_csv(file_with_commas, ',')\n",
    "```\n",
    "\n",
    "### From `postgreSQL` database\n",
    "Another common data source for sales transactions might be some sort of database. `bestPy` therefore provides a reader for the popular and open `postgreSQL` database. Specifically, we assume that in your database you have a table that conceptually mirrors the structure of the CSV file, that is, the table has three columns (or _fields_) containing the resepctive information.\n",
    "\n",
    "To access the database containing that table, quite a number of parameters need to be specified. To facilitate the process, `bestPy` requires you to _fill out a form_, which we import like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bestPy.datastructures import PostgreSQLparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a fresh copy of the form by creating an instance of `PostgreSQLparams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = PostgreSQLparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, Tab completion is your friend. You might want to start with filling in the fields that start with \"`login_`\". The `login` attribute itself allows you to monitor progress. It represents the current login string that will eventually be sent to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<dbname> <host> <password> <user>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dbname='my_database' host='my_host' <password> <user>\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.login_db_name = 'my_database'\n",
    "database.login_host = 'my_host'\n",
    "database.login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of, course, you can also query the individual attributes. Note how they are prepended such the database will understand your login credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbname='my_database'\n",
      "host='my_host'\n"
     ]
    }
   ],
   "source": [
    "print(database.login_db_name)\n",
    "print(database.login_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the login fields and then move on to provide the name of the table ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my_table'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.login_user = 'my_user'\n",
    "database.login_password = 'my_pwd'\n",
    "print(database.table)\n",
    "database.table = 'my_table'\n",
    "database.table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... as well as the _timestamp_, _user_ID_, and _itemID_ column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database.userID = 'my_cutomer_column'\n",
    "database.itemID = 'my_article_column'\n",
    "database.timestamp = 'my_time_column'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, specify the maximum number of transactions you want to retrieve from the database. If you simply want all there are, then say so by specifying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.limit = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have completed the form, you can used the `from_postgreSQL()` class method of `Transactions` to read the transaction data.\n",
    "\n",
    "```python\n",
    "data = Transactions.from_postgreSQL(database)\n",
    "```\n",
    "Either way, we now have our data and it is time to inspect the\n",
    "\n",
    "### Attributes of `Transactions` data objects\n",
    "Let's go back to the `data` object we created from the CSV file. Remember that we got two warning becasue the two header lines were not interpreted as actual transactions? Well, this fact is reflected in the aptly named attribute `number_of_corrupted_records`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.number_of_corrupted_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importanty, the number of OK transaction can be retrieved through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.number_of_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on customers and articles is held in the `user` and `item` atrributes, respectively. How many there are of each sort, for example, can be extracted like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38747\n",
      "8255\n"
     ]
    }
   ],
   "source": [
    "print(data.user.count)\n",
    "print(data.item.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whatever the actual customer and article IDs are in the data, `bestPy` internally assigns a unique integer index to each customer and each article. To find out which integer index corresponds to which (potentially alphanumeric) ID, use the respective dictionaries `id_of` and `index_of`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "356\n"
     ]
    }
   ],
   "source": [
    "print(data.user.id_of[0])\n",
    "print(data.item.index_of['NI743EL91KBWALID-6808'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data itself is stored in the `matrix` attribute, where rows are customers, columns are articles, and entries are how often a given customer bought a given article. Feel free to eplore the attributes of the `matrix` object by yourself! Here, we are just going to mention that the number of non-zero entries in that matrix, that is, the number of unique cutomer-article pairings in the data can be retrieved as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66947"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.number_of_userItem_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
